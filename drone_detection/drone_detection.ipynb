{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detectorn2 on Windows/Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, we've used the idea from [this video](https://www.youtube.com/watch?v=8eLHZ0R5nHQ) and if in any situation you have to use windows, follow [these steps](https://stackoverflow.com/questions/60631933/install-detectron2-on-windows-10/) to install detectron.\n",
    "\n",
    "### Task\n",
    "\n",
    "Here, we are trying to train a detectron which could detect drones from a still image or from a video stream. We will keep on improving this but this is a very simple startup example.\n",
    "\n",
    "### Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cython pyyaml\n",
    "!pip install -q -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you are using linux, run the below cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/facebookresearch/detectron2 ../detectron2_repo\n",
    "!pip install -q -e ../detectron2_repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.data.datasets import register_coco_instances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we're registering the json annotations and the image folder to some experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_instances('experiment_drone_1', {}, 'D:/Dataset/drone_images/annotations/annotations.json', 'D:/Dataset/drone_images/drone_images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 11:52:00 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/19 11:52:00 d2.data.datasets.coco]: \u001b[0mLoaded 20 images in COCO format from D:/Dataset/drone_images/annotations/annotations.json\n"
     ]
    }
   ],
   "source": [
    "sample_metadata = MetadataCatalog.get('experiment_drone_1')\n",
    "dataset_dicts = DatasetCatalog.get('experiment_drone_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializes Training\n",
    "\n",
    "Here, we'll choose the model `faster_rcnn_R_50_FPN_3x.yaml` to train and fit our dataset on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "import os\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"experiment_drone_1\",)\n",
    "cfg.DATASETS.TEST = ()   # no metrics implemented for this dataset\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")# initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.02\n",
    "cfg.SOLVER.MAX_ITER = 600   # 300 iterations seems good enough, but you can certainly train longer\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # 3 classes (Person, Helmet, Car)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/19 12:43:01 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 12:43:01 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/19 12:43:01 d2.data.datasets.coco]: \u001b[0mLoaded 20 images in COCO format from D:/Dataset/drone_images/annotations/annotations.json\n",
      "\u001b[32m[03/19 12:43:01 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[03/19 12:43:01 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   drone    | 20           |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[03/19 12:43:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/19 12:43:01 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/19 12:43:01 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/19 12:43:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 12:43:01 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_280758.pkl: 167MB [00:13, 12.0MB/s]                               \n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/19 12:44:19 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/19 12:44:40 d2.utils.events]: \u001b[0m eta: 0:04:57  iter: 19  total_loss: 1.051  loss_cls: 0.4157  loss_box_reg: 0.4668  loss_rpn_cls: 0.002457  loss_rpn_loc: 0.007596  time: 0.5918  data_time: 0.2372  lr: 0.0006527  max_mem: 2517M\n",
      "\u001b[32m[03/19 12:44:53 d2.utils.events]: \u001b[0m eta: 0:05:00  iter: 39  total_loss: 0.5814  loss_cls: 0.13  loss_box_reg: 0.4151  loss_rpn_cls: 0.002173  loss_rpn_loc: 0.005751  time: 0.6031  data_time: 0.0797  lr: 0.0013187  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:45:05 d2.utils.events]: \u001b[0m eta: 0:04:49  iter: 59  total_loss: 0.4774  loss_cls: 0.08088  loss_box_reg: 0.379  loss_rpn_cls: 0.0003785  loss_rpn_loc: 0.006366  time: 0.6024  data_time: 0.0929  lr: 0.0019847  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:45:17 d2.utils.events]: \u001b[0m eta: 0:04:46  iter: 79  total_loss: 0.3525  loss_cls: 0.06544  loss_box_reg: 0.2837  loss_rpn_cls: 0.000149  loss_rpn_loc: 0.004821  time: 0.6074  data_time: 0.1022  lr: 0.0026507  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:45:30 d2.utils.events]: \u001b[0m eta: 0:04:34  iter: 99  total_loss: 0.3109  loss_cls: 0.04848  loss_box_reg: 0.264  loss_rpn_cls: 0.000185  loss_rpn_loc: 0.003275  time: 0.6148  data_time: 0.1218  lr: 0.0033167  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:45:43 d2.utils.events]: \u001b[0m eta: 0:04:24  iter: 119  total_loss: 0.2525  loss_cls: 0.05412  loss_box_reg: 0.1926  loss_rpn_cls: 0.0002332  loss_rpn_loc: 0.003244  time: 0.6189  data_time: 0.0909  lr: 0.0039827  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:45:56 d2.utils.events]: \u001b[0m eta: 0:04:17  iter: 139  total_loss: 0.2427  loss_cls: 0.03354  loss_box_reg: 0.2092  loss_rpn_cls: 9.333e-05  loss_rpn_loc: 0.003171  time: 0.6260  data_time: 0.1042  lr: 0.0046487  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:46:11 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 159  total_loss: 0.2578  loss_cls: 0.03644  loss_box_reg: 0.2072  loss_rpn_cls: 0.0002618  loss_rpn_loc: 0.003308  time: 0.6389  data_time: 0.1613  lr: 0.0053147  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:46:25 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 179  total_loss: 0.236  loss_cls: 0.04301  loss_box_reg: 0.1865  loss_rpn_cls: 0.0006842  loss_rpn_loc: 0.003676  time: 0.6444  data_time: 0.1289  lr: 0.0059807  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:46:46 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 199  total_loss: 0.2326  loss_cls: 0.03782  loss_box_reg: 0.1891  loss_rpn_cls: 0.0004455  loss_rpn_loc: 0.002644  time: 0.6882  data_time: 0.3464  lr: 0.0066467  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:47:08 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 219  total_loss: 0.2058  loss_cls: 0.03318  loss_box_reg: 0.1775  loss_rpn_cls: 0.0003402  loss_rpn_loc: 0.002277  time: 0.7253  data_time: 0.3434  lr: 0.0073127  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:47:30 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 239  total_loss: 0.2101  loss_cls: 0.03265  loss_box_reg: 0.1664  loss_rpn_cls: 0.0004475  loss_rpn_loc: 0.002666  time: 0.7554  data_time: 0.3628  lr: 0.0079787  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:47:50 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 259  total_loss: 0.1813  loss_cls: 0.03086  loss_box_reg: 0.1492  loss_rpn_cls: 0.0005297  loss_rpn_loc: 0.002434  time: 0.7766  data_time: 0.3049  lr: 0.0086447  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:48:11 d2.utils.events]: \u001b[0m eta: 0:03:44  iter: 279  total_loss: 0.1816  loss_cls: 0.02825  loss_box_reg: 0.1554  loss_rpn_cls: 0.000426  loss_rpn_loc: 0.002283  time: 0.7945  data_time: 0.3094  lr: 0.0093107  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:48:31 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 299  total_loss: 0.2087  loss_cls: 0.03075  loss_box_reg: 0.1748  loss_rpn_cls: 0.0003992  loss_rpn_loc: 0.002457  time: 0.8091  data_time: 0.2783  lr: 0.0099767  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:48:51 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 319  total_loss: 0.2076  loss_cls: 0.02651  loss_box_reg: 0.1664  loss_rpn_cls: 0.0004847  loss_rpn_loc: 0.002448  time: 0.8208  data_time: 0.2839  lr: 0.010643  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:49:10 d2.utils.events]: \u001b[0m eta: 0:03:17  iter: 339  total_loss: 0.1698  loss_cls: 0.03097  loss_box_reg: 0.1405  loss_rpn_cls: 0.0004589  loss_rpn_loc: 0.002614  time: 0.8292  data_time: 0.2531  lr: 0.011309  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:49:29 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 359  total_loss: 0.1725  loss_cls: 0.02654  loss_box_reg: 0.1404  loss_rpn_cls: 0.0003522  loss_rpn_loc: 0.002585  time: 0.8352  data_time: 0.2217  lr: 0.011975  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:49:48 d2.utils.events]: \u001b[0m eta: 0:02:53  iter: 379  total_loss: 0.189  loss_cls: 0.0261  loss_box_reg: 0.1583  loss_rpn_cls: 0.0005252  loss_rpn_loc: 0.00267  time: 0.8421  data_time: 0.2478  lr: 0.012641  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:50:08 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 399  total_loss: 0.1712  loss_cls: 0.0282  loss_box_reg: 0.1356  loss_rpn_cls: 0.0004782  loss_rpn_loc: 0.002297  time: 0.8487  data_time: 0.2531  lr: 0.013307  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:50:28 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 419  total_loss: 0.1714  loss_cls: 0.02751  loss_box_reg: 0.1425  loss_rpn_cls: 0.0006564  loss_rpn_loc: 0.003279  time: 0.8552  data_time: 0.2541  lr: 0.013973  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:50:46 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 439  total_loss: 0.1474  loss_cls: 0.02216  loss_box_reg: 0.1219  loss_rpn_cls: 0.0004532  loss_rpn_loc: 0.003105  time: 0.8591  data_time: 0.2285  lr: 0.014639  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:51:06 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 459  total_loss: 0.1624  loss_cls: 0.02071  loss_box_reg: 0.1369  loss_rpn_cls: 0.0007725  loss_rpn_loc: 0.002488  time: 0.8638  data_time: 0.2383  lr: 0.015305  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:51:27 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 479  total_loss: 0.1727  loss_cls: 0.02646  loss_box_reg: 0.1436  loss_rpn_cls: 0.0004571  loss_rpn_loc: 0.002179  time: 0.8723  data_time: 0.3833  lr: 0.015971  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:51:51 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 499  total_loss: 0.1522  loss_cls: 0.02778  loss_box_reg: 0.1174  loss_rpn_cls: 0.0007631  loss_rpn_loc: 0.002614  time: 0.8859  data_time: 0.4572  lr: 0.016637  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:52:15 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 519  total_loss: 0.149  loss_cls: 0.02648  loss_box_reg: 0.1276  loss_rpn_cls: 0.0008137  loss_rpn_loc: 0.002932  time: 0.8982  data_time: 0.4555  lr: 0.017303  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:53:01 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 539  total_loss: 0.1338  loss_cls: 0.02751  loss_box_reg: 0.112  loss_rpn_cls: 0.0006316  loss_rpn_loc: 0.001996  time: 0.9502  data_time: 1.3875  lr: 0.017969  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:53:57 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 559  total_loss: 0.1466  loss_cls: 0.02385  loss_box_reg: 0.1184  loss_rpn_cls: 0.0004145  loss_rpn_loc: 0.002913  time: 1.0162  data_time: 1.8063  lr: 0.018635  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:54:52 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 579  total_loss: 0.1512  loss_cls: 0.02238  loss_box_reg: 0.1301  loss_rpn_cls: 0.0008837  loss_rpn_loc: 0.003121  time: 1.0760  data_time: 1.7768  lr: 0.019301  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:55:49 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 599  total_loss: 0.1355  loss_cls: 0.01653  loss_box_reg: 0.1113  loss_rpn_cls: 0.0009112  loss_rpn_loc: 0.002301  time: 1.1313  data_time: 1.7357  lr: 0.019967  max_mem: 2731M\n",
      "\u001b[32m[03/19 12:55:49 d2.engine.hooks]: \u001b[0mOverall training speed: 598 iterations in 0:11:16 (1.1313 s / it)\n",
      "\u001b[32m[03/19 12:55:49 d2.engine.hooks]: \u001b[0mTotal training time: 0:11:19 (0:00:03 on hooks)\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=True)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.95   # the testing threshold for this model\n",
    "# cfg.DATASETS.TEST = (\"experiment_drone_1\",)\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locate drone in the new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "im = cv2.imread('D:/Dataset/drone_images/drone_images_test/' + str(d) + '.jpg')\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im,\n",
    "                metadata=sample_metadata, \n",
    "                scale=0.8, \n",
    "                instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    ")\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "result_image = v.get_image()\n",
    "cv2.imwrite('D:/Dataset/drone_images/results/' + str(d) + '.jpg', result_image)\n",
    "# cv2.imshow(np.ndarray(v.get_image()[:, :, ::-1]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe1fbfa14f7916735696a9322e667a237902258ca1fb6b99eeb22f79e9159140"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
